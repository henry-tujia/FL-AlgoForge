{"cells":[{"cell_type":"code","execution_count":208,"metadata":{},"outputs":[],"source":["import torch\n","import sys\n","sys.path.append('/mnt/data/th')\n","from models.resnet_fednonlocal import resnet as resnet_nonlocal_server\n","from models.resnet_fednonlocal import resnet_nonlocal"]},{"cell_type":"code","execution_count":209,"metadata":{},"outputs":[],"source":["from models.resnet_fednonlocal import ResnetBlock,NonLocalBlockND,Classfier\n","from torch import nn\n","\n","class resnet_nonlocal(nn.Module):\n","    def __init__(self, blocks=2, input_nc=3, feature_dim=784, net_mode='resnet', in_channels=4, numclass=10) -> None:\n","        super(resnet_nonlocal, self).__init__()\n","\n","        self.encoder_local_layer_0 = nn.Sequential(\n","            nn.Conv2d(input_nc, 16, kernel_size=3, padding=0, bias=True),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU(True)\n","        )\n","\n","        self.encoder_local_layer_1 = nn.Sequential(\n","            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=0, bias=True),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(True)\n","        )\n","\n","        self.encoder_local_layer_2 = ResnetBlock(32, padding_type='reflect',\n","                                  norm_layer=nn.BatchNorm2d, use_dropout=False, use_bias=True)\n","        \n","        self.encoder_local_layer_3 = ResnetBlock(32, padding_type='reflect',\n","                                  norm_layer=nn.BatchNorm2d, use_dropout=False, use_bias=True)\n","\n","        self.encoder_local_layer_4 = nn.Conv2d(32, 4, kernel_size=1)\n","\n","        self.encoder_new_layer_0 = nn.Sequential(\n","            nn.Conv2d(input_nc, 16, kernel_size=3, padding=0, bias=True),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU(True)\n","        )\n","\n","        self.encoder_new_layer_1 = nn.Sequential(\n","            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=0, bias=True),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(True)\n","        )\n","\n","        self.encoder_new_layer_2 = ResnetBlock(32, padding_type='reflect',\n","                                  norm_layer=nn.BatchNorm2d, use_dropout=False, use_bias=True)\n","        \n","        self.encoder_new_layer_3 = ResnetBlock(32, padding_type='reflect',\n","                                  norm_layer=nn.BatchNorm2d, use_dropout=False, use_bias=True)\n","\n","        self.encoder_new_layer_4 = nn.Conv2d(32, 4, kernel_size=1)\n","\n","        self.block = nn.Sequential(\n","            nn.Tanh()\n","        )\n","        self.Nonlocal_1 = NonLocalBlockND(in_channels)\n","        self.classfier = Classfier(feature_dim, 256, 128)\n","        self.out = nn.Sequential(\n","            nn.Linear(128, numclass)\n","        )\n","\n","    def forward(self, x):\n","        \n","        x_local = self.encoder_local_layer_0(x)\n","        x_local = self.encoder_local_layer_1(x_local)\n","        x_local = self.encoder_local_layer_2(x_local)\n","        x_local = self.encoder_local_layer_3(x_local)\n","        x_local = self.encoder_local_layer_4(x_local)\n","\n","        x_new = self.encoder_new_layer_0(x)\n","        x_new = self.encoder_new_layer_1(x_new)\n","        x_new = self.encoder_new_layer_2(x_new)\n","        x_new = self.encoder_new_layer_3(x_new)\n","        x_new = self.encoder_new_layer_4(x_new)\n","\n","        x_combine_1 = self.Nonlocal_1(x_new, x_local)\n","\n","        x_combine_1 = self.block(x_combine_1)\n","\n","        x_combine_ = torch.flatten(x_combine_1, start_dim=1)\n","        logs = self.out(self.classfier(x_combine_))\n","\n","        return logs\n","\n","    def change_paras(self):\n","        self.encoder_local.load_state_dict(self.encoder_new.state_dict())\n","\n","\n","class resnet(nn.Module):\n","    def __init__(self, blocks=2, input_nc=3, feature_dim=784, net_mode='resnet', in_channels=4, numclass=10, KD=False) -> None:\n","        super(resnet, self).__init__()\n","\n","        self.encoder_new_layer_0 = nn.Sequential(\n","            nn.Conv2d(input_nc, 16, kernel_size=3, padding=0, bias=True),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU(True)\n","        )\n","\n","        self.encoder_new_layer_1 = nn.Sequential(\n","            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=0, bias=True),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(True)\n","        )\n","\n","        self.encoder_new_layer_2 = ResnetBlock(32, padding_type='reflect',\n","                                  norm_layer=nn.BatchNorm2d, use_dropout=False, use_bias=True)\n","        \n","        self.encoder_new_layer_3 = ResnetBlock(32, padding_type='reflect',\n","                                  norm_layer=nn.BatchNorm2d, use_dropout=False, use_bias=True)\n","\n","        self.encoder_new_layer_4 = nn.Conv2d(32, 4, kernel_size=1)\n","\n","        self.block = nn.Sequential(\n","            nn.Tanh()\n","        )\n","        self.classfier = Classfier(feature_dim, 256, 128)\n","        self.out = nn.Sequential(\n","            nn.Linear(128, numclass)\n","        )\n","        self.KD = KD\n","    def forward(self, x):\n","        x_new = self.encoder_new_layer_0(x)\n","        x_new = self.encoder_new_layer_1(x_new)\n","        x_new = self.encoder_new_layer_2(x_new)\n","        x_new = self.encoder_new_layer_3(x_new)\n","        x_new = self.encoder_new_layer_4(x_new)\n","        x_new = self.block(x_new)\n","        x_combine_ = torch.flatten(x_new, start_dim=1)\n","        x_f = self.classfier(x_combine_)\n","        logs = self.out(x_f)\n","        if self.KD:\n","            return x_f, logs\n","        return logs"]},{"cell_type":"code","execution_count":210,"metadata":{},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":210,"metadata":{},"output_type":"execute_result"}],"source":["#创建全局模型\n","\n","import os\n","\n","model = resnet(feature_dim=576)\n","\n","paras_old = model.state_dict()\n","# print(model.state_dict().keys())\n","\n","# model_1 = resnet_nonlocal_server(feature_dim=576)\n","# print(model_1.state_dict().keys())\n","paras = torch.load(\"/mnt/data/th/FedAlign/logs/20220825_030130__fednonlocal_e10_c100/server.pt\")\n","\n","for key_old,key_new in zip(paras_old.keys(),paras.keys()):\n","    paras_old[key_old] = paras[key_new]\n","\n","model.load_state_dict(paras_old)\n","# print(paras.keys())\n","# model.load_state_dict(paras)\n","# print(model.classfier)"]},{"cell_type":"code","execution_count":211,"metadata":{},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":211,"metadata":{},"output_type":"execute_result"}],"source":["#创建本地模型读取参数\n","local_model = resnet_nonlocal(feature_dim=576)\n","paras_local = local_model.state_dict()\n","\n","for key,value in model.state_dict().items():\n","    if key in paras_local:\n","        paras_local[key] = value\n","\n","local_model.load_state_dict(paras_local)"]},{"cell_type":"code","execution_count":212,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0 current \n","current size for 0 is 185\n","current size for 0 is 185\n","current size for 0 is 185\n","current size for 0 is 185\n","current size for 0 is 185\n","1 current \n","current size for 1 is 185\n","current size for 1 is 185\n","current size for 1 is 185\n","current size for 1 is 185\n","current size for 1 is 185\n","2 current \n","current size for 2 is 185\n","current size for 2 is 185\n","current size for 2 is 185\n","current size for 2 is 185\n","current size for 2 is 185\n","3 current \n","current size for 3 is 185\n","current size for 3 is 185\n","current size for 3 is 185\n","current size for 3 is 185\n","current size for 3 is 185\n"]}],"source":["#创建数据集划分\n","from FedTH.data.digits_feature import prepare_feature_data\n","\n","train_dataloaders, val,test_dataloaders = prepare_feature_data(\"digits+feature\",64,4)"]},{"cell_type":"code","execution_count":213,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["20\n"]}],"source":["print(len(train_dataloaders))\n","train_data = train_dataloaders[0]"]},{"cell_type":"code","execution_count":214,"metadata":{},"outputs":[],"source":["# #训练本地模型（未利用全局信息）\n","# # model = resnet_nonlocal_server(feature_dim=576)\n","# import numpy as np\n","\n","# device = \"cpu\" if not torch.cuda.is_available() else \"cuda\"\n","\n","# device = torch.device(device)\n","\n","# local_model.train()\n","\n","# local_model.to(device)\n","\n","# loss_func = torch.nn.CrossEntropyLoss()\n","# optimize = torch.optim.SGD(local_model.parameters() ,lr=0.01)\n","\n","# for key,paras in local_model.named_parameters():\n","#     if \"encoder_local\" in key:\n","#         paras.requires_grad = False\n","\n","# for epoch in range(10):\n","#     losses = []\n","#     for data,label in train_data:\n","#         data = data.to(device)\n","#         label = label.to(device)\n","\n","#         logits = local_model(data)\n","#         loss = loss_func(logits,label)\n","#         loss.backward()\n","#         losses.append(loss.item())\n","#         # print(\"loss:{}\".format(loss.item()))\n","\n","#         optimize.step()\n","#     losses = np.array(losses)\n","#     print(\"loss:{}\".format(losses.mean()))\n"]},{"cell_type":"code","execution_count":215,"metadata":{},"outputs":[],"source":["import numpy as np\n","\n","device = \"cpu\" if not torch.cuda.is_available() else \"cuda\"\n","\n","device = torch.device(device)\n","\n","loss_func = torch.nn.CrossEntropyLoss()\n"]},{"cell_type":"code","execution_count":216,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["loss:2.2947874863942466\n","loss:2.2132845719655356\n","loss:2.0771918296813965\n","loss:1.8812493483225505\n","loss:1.5981007814407349\n","loss:1.2723294893900554\n","loss:0.982837955156962\n","loss:0.7211032708485922\n","loss:0.45570943752924603\n","loss:0.2744227945804596\n"]}],"source":["model_test = resnet(feature_dim=576)\n","\n","model_test.train()\n","model_test.to(device)\n","\n","optimize = torch.optim.SGD(model_test.parameters() ,lr=0.01)\n","\n","\n","# for key,paras in local_model.named_parameters():\n","#     if \"encoder_local\" in key:\n","#         paras.requires_grad = False\n","\n","for epoch in range(10):\n","    losses = []\n","    for data,label in train_data:\n","        data = data.to(device)\n","        label = label.to(device)\n","\n","        logits = model_test(data)\n","        loss = loss_func(logits,label)\n","        loss.backward()\n","        losses.append(loss.item())\n","        # print(\"loss:{}\".format(loss.item()))\n","\n","        optimize.step()\n","    losses = np.array(losses)\n","    print(\"loss:{}\".format(losses.mean()))\n"]},{"cell_type":"code","execution_count":217,"metadata":{},"outputs":[],"source":["paras = local_model.state_dict()\n","\n","for key,value in model_test.state_dict().items():\n","    if \"new\" in key:\n","        key_new = key.replace(\"new\",\"local\")\n","        if \"encoder\" in key:\n","            paras[key_new] = value\n"]},{"cell_type":"code","execution_count":218,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["loss:0.19248749564091364\n","loss:0.08686068405707677\n","loss:0.02703664420793454\n","loss:0.027423510948816936\n","loss:0.035178675005833306\n","loss:0.021212950348854065\n","loss:0.018091759644448757\n","loss:0.01598774300267299\n","loss:0.014820147305727005\n","loss:0.02919332046682636\n"]}],"source":["\n","\n","optimize = torch.optim.SGD(local_model.parameters() ,lr=0.01)\n","\n","\n","local_model.train()\n","\n","local_model.to(device)\n","\n","# for key,paras in local_model.named_parameters():\n","#     if \"encoder_local\" in key:\n","#         paras.requires_grad = False\n","\n","for epoch in range(10):\n","    losses = []\n","    for data,label in train_data:\n","        data = data.to(device)\n","        label = label.to(device)\n","\n","        logits = local_model(data)\n","        loss = loss_func(logits,label)\n","        loss.backward()\n","        losses.append(loss.item())\n","        # print(\"loss:{}\".format(loss.item()))\n","\n","        optimize.step()\n","    losses = np.array(losses)\n","    print(\"loss:{}\".format(losses.mean()))\n"]},{"cell_type":"code","execution_count":219,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{0: 9, 1: 9, 2: 2, 3: 0, 4: 9, 5: 6, 6: 0, 7: 9, 8: 3, 9: 3, 10: 1, 11: 6, 12: 5, 13: 5, 14: 2, 15: 6, 16: 6, 17: 3, 18: 4, 19: 7, 20: 8, 21: 8, 22: 7, 23: 4, 24: 2, 25: 8, 26: 0, 27: 7, 28: 8, 29: 7, 30: 5, 31: 3, 32: 3, 33: 9, 34: 3, 35: 1, 36: 3, 37: 6, 38: 7, 39: 4, 40: 7, 41: 4, 42: 1, 43: 6, 44: 4, 45: 2, 46: 4, 47: 6, 48: 1, 49: 8, 50: 1, 51: 8, 52: 6, 53: 5, 54: 6, 55: 3, 56: 8, 57: 2, 58: 5, 59: 6, 60: 6, 61: 0, 62: 0, 63: 1, 64: 9, 65: 8, 66: 3, 67: 6, 68: 1, 69: 5, 70: 0, 71: 9, 72: 9, 73: 5, 74: 3, 75: 0, 76: 5, 77: 7, 78: 3, 79: 4, 80: 8, 81: 5, 82: 3, 83: 0, 84: 7, 85: 1, 86: 1, 87: 1, 88: 3, 89: 0, 90: 0, 91: 7, 92: 1, 93: 1, 94: 9, 95: 8, 96: 0, 97: 7, 98: 9, 99: 4, 100: 6, 101: 2, 102: 4, 103: 0, 104: 3, 105: 1, 106: 0, 107: 1, 108: 8, 109: 6, 110: 7, 111: 0, 112: 4, 113: 6, 114: 2, 115: 5, 116: 0, 117: 2, 118: 3, 119: 1, 120: 7, 121: 8, 122: 5, 123: 6, 124: 3, 125: 2, 126: 6, 127: 6, 128: 0, 129: 6, 130: 1, 131: 0, 132: 7, 133: 0, 134: 0, 135: 6, 136: 6, 137: 9, 138: 9, 139: 2, 140: 0, 141: 0, 142: 9, 143: 6, 144: 4, 145: 1, 146: 3, 147: 4, 148: 2, 149: 3, 150: 2, 151: 0, 152: 8, 153: 0, 154: 6, 155: 6, 156: 4, 157: 2, 158: 9, 159: 3, 160: 9, 161: 0, 162: 0, 163: 1, 164: 0, 165: 2, 166: 9, 167: 1, 168: 7, 169: 3, 170: 0, 171: 8, 172: 3, 173: 4, 174: 5, 175: 1, 176: 2, 177: 6, 178: 4, 179: 1, 180: 0, 181: 4, 182: 1, 183: 4, 184: 5, 185: 9, 186: 9, 187: 3, 188: 6, 189: 1, 190: 3, 191: 6, 192: 3, 193: 9, 194: 9, 195: 7, 196: 3, 197: 6, 198: 3, 199: 5, 200: 1, 201: 2, 202: 8, 203: 3, 204: 7, 205: 0, 206: 5, 207: 2, 208: 4, 209: 3, 210: 9, 211: 1, 212: 4, 213: 1, 214: 3, 215: 7, 216: 9, 217: 6, 218: 9, 219: 5, 220: 3, 221: 7, 222: 7, 223: 9, 224: 0, 225: 1, 226: 4, 227: 7, 228: 0, 229: 3, 230: 8, 231: 0, 232: 8, 233: 3, 234: 8, 235: 5, 236: 6, 237: 8, 238: 1, 239: 3, 240: 4, 241: 6, 242: 1, 243: 9, 244: 4, 245: 3, 246: 1, 247: 1, 248: 9, 249: 4, 250: 8, 251: 8, 252: 6, 253: 1, 254: 4, 255: 1, 256: 4, 257: 0, 258: 7, 259: 0, 260: 1, 261: 2, 262: 6, 263: 3, 264: 7, 265: 3, 266: 0, 267: 7, 268: 6, 269: 4, 270: 4, 271: 2, 272: 3, 273: 2, 274: 6, 275: 2, 276: 4, 277: 6, 278: 0, 279: 6, 280: 1, 281: 2, 282: 1, 283: 4, 284: 7, 285: 0, 286: 6, 287: 8, 288: 2, 289: 0, 290: 4, 291: 9, 292: 1, 293: 9, 294: 1, 295: 4, 296: 1, 297: 0, 298: 0, 299: 1, 300: 9, 301: 1, 302: 0, 303: 6, 304: 7, 305: 0, 306: 3, 307: 0, 308: 8, 309: 7, 310: 4, 311: 7, 312: 1, 313: 7, 314: 9, 315: 0, 316: 8, 317: 1, 318: 1, 319: 9, 320: 6, 321: 1, 322: 8, 323: 3, 324: 5, 325: 2, 326: 6, 327: 3, 328: 8, 329: 9, 330: 7, 331: 2, 332: 4, 333: 1, 334: 0, 335: 9, 336: 3, 337: 1, 338: 7, 339: 4, 340: 4, 341: 7, 342: 7, 343: 9, 344: 5, 345: 0, 346: 1, 347: 1, 348: 4, 349: 4, 350: 0, 351: 8, 352: 0, 353: 4, 354: 5, 355: 7, 356: 7, 357: 1, 358: 6, 359: 3, 360: 9, 361: 6, 362: 0, 363: 8, 364: 8, 365: 1, 366: 1, 367: 5, 368: 6, 369: 0, 370: 3, 371: 8, 372: 4, 373: 8, 374: 6, 375: 4, 376: 2, 377: 6, 378: 3, 379: 7, 380: 2, 381: 9, 382: 7, 383: 7, 384: 3, 385: 5, 386: 6, 387: 2, 388: 9, 389: 0, 390: 1, 391: 4, 392: 1, 393: 0, 394: 3, 395: 9, 396: 3, 397: 5, 398: 6, 399: 1, 400: 5, 401: 7, 402: 0, 403: 9, 404: 4, 405: 5, 406: 7, 407: 0, 408: 5, 409: 3, 410: 4, 411: 9, 412: 1, 413: 9, 414: 8, 415: 8, 416: 9, 417: 0, 418: 6, 419: 8, 420: 8, 421: 0, 422: 3, 423: 1, 424: 0, 425: 7, 426: 2, 427: 2, 428: 7, 429: 1, 430: 2, 431: 7, 432: 5, 433: 8, 434: 7, 435: 8, 436: 5, 437: 1, 438: 0, 439: 2, 440: 1, 441: 8, 442: 6, 443: 9, 444: 5, 445: 6, 446: 4, 447: 4, 448: 1, 449: 9, 450: 0, 451: 9, 452: 4, 453: 0, 454: 8, 455: 2, 456: 2, 457: 5, 458: 1, 459: 7, 460: 6, 461: 9, 462: 6, 463: 2, 464: 3, 465: 7, 466: 6, 467: 9, 468: 9, 469: 0, 470: 0, 471: 9, 472: 5, 473: 3, 474: 5, 475: 1, 476: 0, 477: 1, 478: 1, 479: 7, 480: 2, 481: 2, 482: 2, 483: 3, 484: 8, 485: 1, 486: 7, 487: 3, 488: 4, 489: 7, 490: 8, 491: 7, 492: 8, 493: 7, 494: 7, 495: 1, 496: 6, 497: 5, 498: 4, 499: 1, 500: 8, 501: 2, 502: 2, 503: 6, 504: 4, 505: 8, 506: 3, 507: 2, 508: 2, 509: 1, 510: 5, 511: 3, 512: 9, 513: 9, 514: 6, 515: 9, 516: 7, 517: 9, 518: 1, 519: 5, 520: 5, 521: 5, 522: 2, 523: 6, 524: 8, 525: 0, 526: 1, 527: 7, 528: 5, 529: 3, 530: 2, 531: 7, 532: 4, 533: 1, 534: 8, 535: 4, 536: 1, 537: 9, 538: 0, 539: 6, 540: 3, 541: 5, 542: 4, 543: 9, 544: 5, 545: 3, 546: 3, 547: 2, 548: 7, 549: 2, 550: 4, 551: 7, 552: 3, 553: 8, 554: 5, 555: 9, 556: 5, 557: 5, 558: 4, 559: 0, 560: 2, 561: 5, 562: 6, 563: 3, 564: 0, 565: 6, 566: 6, 567: 4, 568: 4, 569: 3, 570: 4, 571: 2, 572: 9, 573: 4, 574: 6, 575: 1, 576: 8, 577: 4, 578: 1, 579: 5, 580: 1, 581: 1, 582: 9, 583: 2, 584: 9, 585: 4, 586: 6, 587: 0, 588: 4, 589: 4, 590: 4, 591: 3, 592: 6, 593: 8, 594: 4, 595: 5, 596: 9, 597: 2, 598: 6, 599: 0, 600: 1, 601: 9, 602: 9, 603: 6, 604: 9, 605: 3, 606: 0, 607: 9, 608: 9, 609: 6, 610: 9, 611: 9, 612: 7, 613: 3, 614: 2, 615: 6, 616: 1, 617: 0, 618: 4, 619: 6, 620: 7, 621: 3, 622: 9, 623: 2, 624: 8, 625: 7, 626: 5, 627: 9, 628: 0, 629: 7, 630: 6, 631: 6, 632: 0, 633: 4, 634: 0, 635: 7, 636: 5, 637: 0, 638: 2, 639: 0, 640: 7, 641: 0, 642: 3, 643: 9, 644: 6, 645: 1, 646: 5, 647: 1, 648: 3, 649: 9, 650: 9, 651: 7, 652: 3, 653: 0, 654: 2, 655: 6, 656: 2, 657: 1, 658: 1, 659: 3, 660: 7, 661: 8, 662: 9, 663: 1, 664: 4, 665: 1, 666: 3, 667: 2, 668: 4, 669: 4, 670: 1, 671: 8, 672: 4, 673: 0, 674: 3, 675: 0, 676: 1, 677: 6, 678: 7, 679: 6, 680: 6, 681: 6, 682: 8, 683: 0, 684: 1, 685: 0, 686: 1, 687: 3, 688: 9, 689: 1, 690: 9, 691: 3, 692: 7, 693: 9, 694: 4, 695: 7, 696: 3, 697: 4, 698: 6, 699: 5, 700: 7, 701: 5, 702: 1, 703: 8, 704: 1, 705: 7, 706: 9, 707: 7, 708: 9, 709: 4, 710: 8, 711: 1, 712: 6, 713: 5, 714: 8, 715: 1, 716: 3, 717: 9, 718: 9, 719: 8, 720: 8, 721: 4, 722: 5, 723: 9, 724: 3, 725: 1, 726: 2, 727: 4, 728: 8, 729: 3, 730: 5, 731: 7, 732: 8, 733: 9, 734: 0, 735: 9, 736: 2, 737: 6, 738: 2, 739: 1, 740: 7, 741: 2, 742: 4}\n"]}],"source":["from torchvision import transforms\n","\n","transform_mnist = transforms.Compose([\n","            transforms.Grayscale(num_output_channels=3),\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","        ])\n","\n","from FedBN.utils.data_utils import DigitsDataset\n","\n","mnist_trainset = DigitsDataset(data_path=\"/mnt/data/th/FedBN/data/MNIST\", channels=1, percent=0.1, train=True,  transform=transform_mnist)\n","\n","imagenet_class_labels = {}\n","\n","for index,(data,label) in enumerate(zip(mnist_trainset.images,mnist_trainset.labels)):\n","    imagenet_class_labels.update({index:label})\n","\n","print(imagenet_class_labels)"]},{"cell_type":"code","execution_count":189,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["resnet_nonlocal(\n","  (encoder_local_layer_0): Sequential(\n","    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n","    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (encoder_local_layer_1): Sequential(\n","    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n","    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (encoder_local_layer_2): ResnetBlock(\n","    (conv_block): Sequential(\n","      (0): ReflectionPad2d((1, 1, 1, 1))\n","      (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n","      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (3): ReLU(inplace=True)\n","      (4): ReflectionPad2d((1, 1, 1, 1))\n","      (5): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n","      (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (encoder_local_layer_3): ResnetBlock(\n","    (conv_block): Sequential(\n","      (0): ReflectionPad2d((1, 1, 1, 1))\n","      (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n","      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (3): ReLU(inplace=True)\n","      (4): ReflectionPad2d((1, 1, 1, 1))\n","      (5): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n","      (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (encoder_local_layer_4): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))\n","  (encoder_new_layer_0): Sequential(\n","    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n","    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (encoder_new_layer_1): Sequential(\n","    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n","    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (encoder_new_layer_2): ResnetBlock(\n","    (conv_block): Sequential(\n","      (0): ReflectionPad2d((1, 1, 1, 1))\n","      (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n","      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (3): ReLU(inplace=True)\n","      (4): ReflectionPad2d((1, 1, 1, 1))\n","      (5): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n","      (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (encoder_new_layer_3): ResnetBlock(\n","    (conv_block): Sequential(\n","      (0): ReflectionPad2d((1, 1, 1, 1))\n","      (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n","      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (3): ReLU(inplace=True)\n","      (4): ReflectionPad2d((1, 1, 1, 1))\n","      (5): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n","      (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (encoder_new_layer_4): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))\n","  (block): Sequential(\n","    (0): Tanh()\n","  )\n","  (Nonlocal_1): NonLocalBlockND(\n","    (g): Sequential(\n","      (0): Conv2d(4, 2, kernel_size=(1, 1), stride=(1, 1))\n","      (1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n","    )\n","    (W): Sequential(\n","      (0): Conv2d(2, 4, kernel_size=(1, 1), stride=(1, 1))\n","      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (theta): Conv2d(4, 2, kernel_size=(1, 1), stride=(1, 1))\n","    (phi): Sequential(\n","      (0): Conv2d(4, 2, kernel_size=(1, 1), stride=(1, 1))\n","      (1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n","    )\n","  )\n","  (classfier): Classfier(\n","    (classfier): Sequential(\n","      (0): Linear(in_features=576, out_features=256, bias=True)\n","      (1): Linear(in_features=256, out_features=128, bias=True)\n","    )\n","  )\n","  (out): Sequential(\n","    (0): Linear(in_features=128, out_features=10, bias=True)\n","  )\n",")\n"]}],"source":["print(local_model)"]},{"cell_type":"code","execution_count":223,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["from explainable_cnn import CNNExplainer\n","\n","x_cnn = CNNExplainer(model_test, imagenet_class_labels)\n","\n","# image = mnist_trainset.images[0]\n","\n","# toPIL = transforms.ToPILImage()\n","\n","# pic = toPIL(image)\n","\n","# pic.save('9.jpg')\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","# plt.imshow(pic)\n","grad_cams  = x_cnn.get_grad_cam(\n","    \"./9.jpg\",\n","    3, # La    bel corresponding to Shark. You can pass either 3 or \"tiger shark, Galeocerdo cuvieri\",\n","    (28, 28),\n","    [\"encoder_new_layer_4\"]#,\"encoder_local_layer_4\",\"Nonlocal_1\"\n",")\n","\n","plt.imshow(grad_cams[0].astype('uint8'))\n","plt.show()\n","# plt.imshow(grad_cams[1].astype('uint8'))\n","# plt.show()\n","# plt.imshow(grad_cams[2].astype('uint8'))\n","# plt.show()"]},{"cell_type":"code","execution_count":102,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",")\n"]}],"source":["from torchvision import models\n","\n","model = models.resnet18()\n","print(model)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ResNet(\n","  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=256, out_features=10, bias=True)\n","  (p1): Linear(in_features=256, out_features=256, bias=True)\n","  (p2): Linear(in_features=256, out_features=256, bias=True)\n",")\n"]}],"source":["from models.resnet import resnet56\n","\n","model = resnet56(10, KD=True, projection=True)\n","\n","print(model)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.7.12 ('th')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \n[GCC 9.4.0]"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"50e91cb8a21f45f90d8a5748a479a7f2d0d1c154c3a41e423e45c4f7a6a859a2"}}},"nbformat":4,"nbformat_minor":2}
